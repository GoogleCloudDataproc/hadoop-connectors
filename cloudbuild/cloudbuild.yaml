# Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

substitutions:
  _ZONAL_BUCKET_NAME: 'gcs-zonal-test-bucket-${BUILD_ID}'

steps:
  # 1. Create a Docker image containing hadoop-connectors repo
  - name: 'gcr.io/cloud-builders/docker'
    id: 'docker-build'
    args: ['build', '--tag=gcr.io/$PROJECT_ID/dataproc-hadoop-connectors-presubmit', '-f', 'cloudbuild/Dockerfile', '.']

  # 2. Run unit tests
  - name: 'gcr.io/$PROJECT_ID/dataproc-hadoop-connectors-presubmit'
    id: 'unit-tests'
    waitFor: ['docker-build']
    entrypoint: 'bash'
    args: ['/hadoop-connectors/cloudbuild/presubmit.sh', 'unittest']
    env:
      - 'CODECOV_TOKEN=$_CODECOV_TOKEN'
      - 'VCS_BRANCH_NAME=$BRANCH_NAME'
      - 'VCS_COMMIT_ID=$COMMIT_SHA'
      - 'VCS_TAG=$TAG_NAME'
      - 'CI_BUILD_ID=$BUILD_ID'

  # 3. Create the Zonal Bucket for integration tests
  - name: 'gcr.io/google.com/cloudsdktool/google-cloud-sdk'
    id: 'create-zonal-bucket'
    waitFor: [ 'docker-build' ]
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        set -euxo pipefail
        WORKER_ZONE_FULL_PATH=$$(curl -s "http://metadata.google.internal/computeMetadata/v1/instance/zone" -H "Metadata-Flavor: Google")
        WORKER_ZONE=$$(echo "$$WORKER_ZONE_FULL_PATH" | awk -F/ '{print $$NF}')
        echo "Creating zonal bucket gs://${_ZONAL_BUCKET_NAME} in zone $$WORKER_ZONE..."
        gcloud storage buckets create gs://${_ZONAL_BUCKET_NAME} \
          --location=us-central1 \
          --placement=$$WORKER_ZONE

  # 4. Run integration tests
  - name: 'gcr.io/$PROJECT_ID/dataproc-hadoop-connectors-presubmit'
    id: 'integration-tests'
    waitFor: ['docker-build','create-zonal-bucket']
    entrypoint: 'bash'
    args: ['/hadoop-connectors/cloudbuild/presubmit.sh', 'integrationtest']
    env:
      - 'GCS_TEST_PROJECT_ID=$PROJECT_ID'
      - 'GCS_ZONAL_TEST_BUCKET=${_ZONAL_BUCKET_NAME}'
      - 'CODECOV_TOKEN=$_CODECOV_TOKEN'
      - 'VCS_BRANCH_NAME=$BRANCH_NAME'
      - 'VCS_COMMIT_ID=$COMMIT_SHA'
      - 'VCS_TAG=$TAG_NAME'
      - 'CI_BUILD_ID=$BUILD_ID'
      - 'GCS_TEST_DIRECT_PATH_PREFERRED=false'

  # 5. Cleanup the Zonal Bucket after tests complete (success or failure)
  - name: 'gcr.io/google.com/cloudsdktool/google-cloud-sdk'
    id: 'cleanup-zonal-bucket'
    entrypoint: 'bash'
    args:
      - '-c'
      - 'gcloud storage rm --recursive gs://${_ZONAL_BUCKET_NAME} || true'

# Tests take on average 25 minutes to run
timeout: 2400s

options:
  pool:
    name: 'projects/cloud-dataproc-ci/locations/us-central1/workerPools/integ-test-connector-pool'

