steps:
  # 1. Create a Docker image containing bigdata-interop repo
  - name: 'gcr.io/cloud-builders/docker'
    id: 'docker-build'
    args: ['build', '--tag=gcr.io/$PROJECT_ID/dataproc-bigdata-interop-presubmit', '-f', 'cloudbuild/Dockerfile', '.']

  # 2. Run Hadoop 2 unit tests concurrently
  - name: 'gcr.io/$PROJECT_ID/dataproc-bigdata-interop-presubmit'
    id: 'unit-tests-hadoop2'
    waitFor: ['docker-build']
    entrypoint: 'bash'
    args: ['/bigdata-interop/cloudbuild/presubmit.sh', 'hadoop2']
    env:
      - 'CODECOV_TOKEN=$_CODECOV_TOKEN'
      - 'VCS_BRANCH_NAME=$BRANCH_NAME'
      - 'VCS_COMMIT_ID=$COMMIT_SHA'
      - 'VCS_TAG=$TAG_NAME'
      - 'CI_BUILD_ID=$BUILD_ID'

  # 3. Run Hadoop 3 unit tests concurrently
  - name: 'gcr.io/$PROJECT_ID/dataproc-bigdata-interop-presubmit'
    id: 'unit-tests-hadoop3'
    waitFor: ['docker-build']
    entrypoint: 'bash'
    args: ['/bigdata-interop/cloudbuild/presubmit.sh', 'hadoop3']
    env:
      - 'CODECOV_TOKEN=$_CODECOV_TOKEN'
      - 'VCS_BRANCH_NAME=$BRANCH_NAME'
      - 'VCS_COMMIT_ID=$COMMIT_SHA'
      - 'VCS_TAG=$TAG_NAME'
      - 'CI_BUILD_ID=$BUILD_ID'
    
options:
  machineType: 'N1_HIGHCPU_8'
